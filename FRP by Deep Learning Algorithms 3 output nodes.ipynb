{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as tls\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorize & select required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24029, 104)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"all_files_spi.csv\")\n",
    "H = []\n",
    "D = []\n",
    "A = []\n",
    "\n",
    "print(df.shape)\n",
    "for i in range(len(df['FTR'])):\n",
    "    if df['FTR'][i] == \"H\":\n",
    "        H.append(1)\n",
    "        A.append(0)\n",
    "        D.append(0)\n",
    "    if df['FTR'][i] == \"D\":\n",
    "        H.append(0)\n",
    "        A.append(0)\n",
    "        D.append(1)\n",
    "    if df['FTR'][i] == \"A\":\n",
    "        H.append(0)\n",
    "        A.append(1)\n",
    "        D.append(0)\n",
    "        #df['D'][i] = 0\n",
    "       # df['A'][i] = 0\n",
    "df['H']= H\n",
    "df['D']= D\n",
    "df['A']= A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['label'] = pd.factorize(df['FTR'])[0]\n",
    "#df['HomeTeam'] = pd.factorize(df['HomeTeam'])[0]\n",
    "#df['AwayTeam'] = pd.factorize(df['AwayTeam'])[0]\n",
    "df['Referee'] = pd.factorize(df['Referee'])[0]\n",
    "df['Div'] = pd.factorize(df['Div'])[0]\n",
    "# 0 = premier league\n",
    "df['Season'] = pd.factorize(df['Season'])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_columns =['Season', 'Div',#'HomeTeam', 'AwayTeam',\n",
    "              'Referee',\n",
    "              \n",
    "              #Bookmakers\n",
    "              'B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'IWH', 'IWD', 'IWA', \n",
    "              'LBH', 'LBD', 'LBA', 'WHH', 'WHD', 'WHA',  \n",
    "              'VCH', 'VCD', 'VCA', \n",
    "              \n",
    "\n",
    "              \n",
    "              # Team dependent feat\n",
    "              # Away Team\n",
    "              'C_AC', 'C_AF', 'C_AR', 'C_AS', 'C_AST', 'C_AY', 'C_FTAG', \"spi_A\",'C_FTAP','F_AT',\n",
    "              \n",
    "              # Home Team\n",
    "              'C_HC', 'C_HF', 'C_HR', 'C_HS', 'C_HST', 'C_HY', 'C_FTHG', \"spi\",'C_FTHP', 'F_HT',\n",
    "              \n",
    "              # Current match --> 'FTHP', 'FTAP',\n",
    "              \n",
    "            \n",
    "             \"spi_A\",\"spi\",\n",
    "              'H','A','D'\n",
    "             ]\n",
    "     \n",
    "\n",
    "df = df[req_columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dd to Np & Fill NaN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stefansamba/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3790: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.fillna(0, inplace=True) # data = np.array(df)\n",
    "\n",
    "\n",
    "data = np.array(df)\n",
    "#data = data / (data.max(axis=0))\n",
    "#data = np.nan_to_num(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "X = data[:,:-3]\n",
    "y = data[:,-3:]\n",
    "\n",
    "X = X / (X.max(axis=0))\n",
    "\n",
    "\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42, shuffle=True) \n",
    "X_train, X_val, y_train, y_val = train_test_split( X_train, y_train, test_size=0.25, random_state=42,shuffle=True)\n",
    "\n",
    "# In this way, train, val, test set will be 60%, 20%, 20% of the dataset respectively.\n",
    "\n",
    "x_len = X_train.shape[1]\n",
    "\n",
    "tot = len(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "len1 = int(len(X_train[1]))\n",
    "print(len1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# number of hidden neurons can vary from 1 to 16\n",
    "#hidden = 16\n",
    "network = models.Sequential()\n",
    "\n",
    "network.add(layers.Dense(10, use_bias='true', activation='sigmoid', input_shape=(len1,)))\n",
    "\n",
    "\n",
    "network.add(layers.Dense(3, use_bias='true', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.initializers.RandomNormal at 0x1a2cbccdd8>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.initializers.RandomNormal(mean=0.0, stddev=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizers.SGD(lr=0.1, momentum=0.0, decay=0.0, nesterov=False)\n",
    "\n",
    "network.compile(optimizer='sgd',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14417 samples, validate on 4806 samples\n",
      "Epoch 1/200\n",
      "14417/14417 [==============================] - 3s 240us/step - loss: 1.1223 - acc: 0.3549 - val_loss: 1.0775 - val_acc: 0.4395\n",
      "Epoch 2/200\n",
      "14417/14417 [==============================] - 1s 81us/step - loss: 1.0750 - acc: 0.4366 - val_loss: 1.0726 - val_acc: 0.4395\n",
      "Epoch 3/200\n",
      "14417/14417 [==============================] - 1s 58us/step - loss: 1.0732 - acc: 0.4366 - val_loss: 1.0723 - val_acc: 0.4395\n",
      "Epoch 4/200\n",
      "14417/14417 [==============================] - 1s 77us/step - loss: 1.0729 - acc: 0.4366 - val_loss: 1.0719 - val_acc: 0.4395\n",
      "Epoch 5/200\n",
      "14417/14417 [==============================] - 2s 108us/step - loss: 1.0726 - acc: 0.4366 - val_loss: 1.0716 - val_acc: 0.4395\n",
      "Epoch 6/200\n",
      "14417/14417 [==============================] - 1s 75us/step - loss: 1.0723 - acc: 0.4366 - val_loss: 1.0714 - val_acc: 0.4395\n",
      "Epoch 7/200\n",
      "14417/14417 [==============================] - 1s 87us/step - loss: 1.0720 - acc: 0.4366 - val_loss: 1.0711 - val_acc: 0.4395\n",
      "Epoch 8/200\n",
      "14417/14417 [==============================] - 1s 61us/step - loss: 1.0717 - acc: 0.4366 - val_loss: 1.0706 - val_acc: 0.4395\n",
      "Epoch 9/200\n",
      "14417/14417 [==============================] - 1s 72us/step - loss: 1.0714 - acc: 0.4366 - val_loss: 1.0703 - val_acc: 0.4395\n",
      "Epoch 10/200\n",
      "14417/14417 [==============================] - 1s 57us/step - loss: 1.0710 - acc: 0.4366 - val_loss: 1.0701 - val_acc: 0.4395\n",
      "Epoch 11/200\n",
      "14417/14417 [==============================] - 1s 58us/step - loss: 1.0707 - acc: 0.4366 - val_loss: 1.0698 - val_acc: 0.4395\n",
      "Epoch 12/200\n",
      "14417/14417 [==============================] - 1s 54us/step - loss: 1.0704 - acc: 0.4366 - val_loss: 1.0692 - val_acc: 0.4395\n",
      "Epoch 13/200\n",
      "14417/14417 [==============================] - 1s 56us/step - loss: 1.0700 - acc: 0.4366 - val_loss: 1.0690 - val_acc: 0.4395\n",
      "Epoch 14/200\n",
      "14417/14417 [==============================] - 1s 54us/step - loss: 1.0696 - acc: 0.4366 - val_loss: 1.0686 - val_acc: 0.4395\n",
      "Epoch 15/200\n",
      "14417/14417 [==============================] - 1s 57us/step - loss: 1.0692 - acc: 0.4366 - val_loss: 1.0682 - val_acc: 0.4395\n",
      "Epoch 16/200\n",
      "14417/14417 [==============================] - 1s 54us/step - loss: 1.0687 - acc: 0.4366 - val_loss: 1.0676 - val_acc: 0.4395\n",
      "Epoch 17/200\n",
      "14417/14417 [==============================] - 1s 54us/step - loss: 1.0683 - acc: 0.4366 - val_loss: 1.0671 - val_acc: 0.4395\n",
      "Epoch 18/200\n",
      "14417/14417 [==============================] - 1s 59us/step - loss: 1.0678 - acc: 0.4366 - val_loss: 1.0666 - val_acc: 0.4395\n",
      "Epoch 19/200\n",
      "14417/14417 [==============================] - 1s 58us/step - loss: 1.0673 - acc: 0.4366 - val_loss: 1.0662 - val_acc: 0.4395\n",
      "Epoch 20/200\n",
      "14417/14417 [==============================] - 1s 52us/step - loss: 1.0668 - acc: 0.4366 - val_loss: 1.0656 - val_acc: 0.4399\n",
      "Epoch 21/200\n",
      "14417/14417 [==============================] - 1s 53us/step - loss: 1.0663 - acc: 0.4366 - val_loss: 1.0651 - val_acc: 0.4399\n",
      "Epoch 22/200\n",
      "14417/14417 [==============================] - 1s 64us/step - loss: 1.0657 - acc: 0.4366 - val_loss: 1.0646 - val_acc: 0.4403\n",
      "Epoch 23/200\n",
      "14417/14417 [==============================] - 1s 70us/step - loss: 1.0651 - acc: 0.4367 - val_loss: 1.0640 - val_acc: 0.4403\n",
      "Epoch 24/200\n",
      "14417/14417 [==============================] - 1s 87us/step - loss: 1.0645 - acc: 0.4368 - val_loss: 1.0633 - val_acc: 0.4407\n",
      "Epoch 25/200\n",
      "14417/14417 [==============================] - 1s 96us/step - loss: 1.0639 - acc: 0.4370 - val_loss: 1.0627 - val_acc: 0.4411\n",
      "Epoch 26/200\n",
      "14417/14417 [==============================] - 1s 82us/step - loss: 1.0632 - acc: 0.4371 - val_loss: 1.0619 - val_acc: 0.4411\n",
      "Epoch 27/200\n",
      "14417/14417 [==============================] - 1s 82us/step - loss: 1.0625 - acc: 0.4380 - val_loss: 1.0610 - val_acc: 0.4413\n",
      "Epoch 28/200\n",
      "14417/14417 [==============================] - 1s 72us/step - loss: 1.0618 - acc: 0.4386 - val_loss: 1.0604 - val_acc: 0.4411\n",
      "Epoch 29/200\n",
      "14417/14417 [==============================] - 1s 55us/step - loss: 1.0610 - acc: 0.4387 - val_loss: 1.0596 - val_acc: 0.4419\n",
      "Epoch 30/200\n",
      "14417/14417 [==============================] - 1s 50us/step - loss: 1.0603 - acc: 0.4400 - val_loss: 1.0590 - val_acc: 0.4438\n",
      "Epoch 31/200\n",
      "14417/14417 [==============================] - 1s 54us/step - loss: 1.0595 - acc: 0.4430 - val_loss: 1.0580 - val_acc: 0.4428\n",
      "Epoch 32/200\n",
      "14417/14417 [==============================] - 1s 53us/step - loss: 1.0587 - acc: 0.4433 - val_loss: 1.0572 - val_acc: 0.4440\n",
      "Epoch 33/200\n",
      "14417/14417 [==============================] - 1s 58us/step - loss: 1.0579 - acc: 0.4443 - val_loss: 1.0565 - val_acc: 0.4476\n",
      "Epoch 34/200\n",
      "14417/14417 [==============================] - 1s 55us/step - loss: 1.0570 - acc: 0.4467 - val_loss: 1.0558 - val_acc: 0.4496\n",
      "Epoch 35/200\n",
      "14417/14417 [==============================] - 1s 62us/step - loss: 1.0562 - acc: 0.4486 - val_loss: 1.0548 - val_acc: 0.4478\n",
      "Epoch 36/200\n",
      "14417/14417 [==============================] - 1s 62us/step - loss: 1.0554 - acc: 0.4498 - val_loss: 1.0539 - val_acc: 0.4505\n",
      "Epoch 37/200\n",
      "14417/14417 [==============================] - 1s 77us/step - loss: 1.0544 - acc: 0.4501 - val_loss: 1.0531 - val_acc: 0.4557\n",
      "Epoch 38/200\n",
      "14417/14417 [==============================] - 1s 55us/step - loss: 1.0536 - acc: 0.4525 - val_loss: 1.0525 - val_acc: 0.4625\n",
      "Epoch 39/200\n",
      "14417/14417 [==============================] - 2s 107us/step - loss: 1.0528 - acc: 0.4558 - val_loss: 1.0515 - val_acc: 0.4625\n",
      "Epoch 40/200\n",
      "14417/14417 [==============================] - 1s 72us/step - loss: 1.0520 - acc: 0.4568 - val_loss: 1.0506 - val_acc: 0.4638\n",
      "Epoch 41/200\n",
      "14417/14417 [==============================] - 1s 70us/step - loss: 1.0511 - acc: 0.4567 - val_loss: 1.0499 - val_acc: 0.4634\n",
      "Epoch 42/200\n",
      "14417/14417 [==============================] - 1s 72us/step - loss: 1.0503 - acc: 0.4588 - val_loss: 1.0492 - val_acc: 0.4636\n",
      "Epoch 43/200\n",
      "14417/14417 [==============================] - 1s 56us/step - loss: 1.0496 - acc: 0.4593 - val_loss: 1.0484 - val_acc: 0.4642\n",
      "Epoch 44/200\n",
      "14417/14417 [==============================] - 1s 58us/step - loss: 1.0488 - acc: 0.4606 - val_loss: 1.0476 - val_acc: 0.4630\n",
      "Epoch 45/200\n",
      "14417/14417 [==============================] - 1s 73us/step - loss: 1.0481 - acc: 0.4597 - val_loss: 1.0470 - val_acc: 0.4661\n",
      "Epoch 46/200\n",
      "14417/14417 [==============================] - 1s 66us/step - loss: 1.0474 - acc: 0.4624 - val_loss: 1.0462 - val_acc: 0.4655\n",
      "Epoch 47/200\n",
      "14417/14417 [==============================] - 1s 59us/step - loss: 1.0468 - acc: 0.4632 - val_loss: 1.0455 - val_acc: 0.4671\n",
      "Epoch 48/200\n",
      "14417/14417 [==============================] - 1s 54us/step - loss: 1.0461 - acc: 0.4644 - val_loss: 1.0450 - val_acc: 0.4684\n",
      "Epoch 49/200\n",
      "14417/14417 [==============================] - 1s 52us/step - loss: 1.0454 - acc: 0.4642 - val_loss: 1.0447 - val_acc: 0.4698\n",
      "Epoch 50/200\n",
      "14417/14417 [==============================] - 1s 52us/step - loss: 1.0446 - acc: 0.4669 - val_loss: 1.0437 - val_acc: 0.4657\n",
      "Epoch 51/200\n",
      "14417/14417 [==============================] - 1s 65us/step - loss: 1.0443 - acc: 0.4654 - val_loss: 1.0432 - val_acc: 0.4682\n",
      "Epoch 52/200\n",
      "14417/14417 [==============================] - 1s 51us/step - loss: 1.0438 - acc: 0.4664 - val_loss: 1.0428 - val_acc: 0.4705\n",
      "Epoch 53/200\n",
      "14417/14417 [==============================] - 1s 73us/step - loss: 1.0433 - acc: 0.4667 - val_loss: 1.0426 - val_acc: 0.4688\n",
      "Epoch 54/200\n",
      "14417/14417 [==============================] - 1s 54us/step - loss: 1.0429 - acc: 0.4677 - val_loss: 1.0418 - val_acc: 0.4696\n",
      "Epoch 55/200\n",
      "14417/14417 [==============================] - 1s 71us/step - loss: 1.0425 - acc: 0.4675 - val_loss: 1.0414 - val_acc: 0.4688\n",
      "Epoch 56/200\n",
      "14417/14417 [==============================] - 1s 50us/step - loss: 1.0421 - acc: 0.4672 - val_loss: 1.0412 - val_acc: 0.4707\n",
      "Epoch 57/200\n",
      "14417/14417 [==============================] - 1s 69us/step - loss: 1.0418 - acc: 0.4684 - val_loss: 1.0408 - val_acc: 0.4698\n",
      "Epoch 58/200\n",
      "14417/14417 [==============================] - 1s 66us/step - loss: 1.0414 - acc: 0.4687 - val_loss: 1.0406 - val_acc: 0.4702\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14417/14417 [==============================] - 1s 68us/step - loss: 1.0411 - acc: 0.4684 - val_loss: 1.0401 - val_acc: 0.4702\n",
      "Epoch 60/200\n",
      "14417/14417 [==============================] - 1s 44us/step - loss: 1.0407 - acc: 0.4686 - val_loss: 1.0402 - val_acc: 0.4694\n",
      "Epoch 61/200\n",
      "14417/14417 [==============================] - 1s 43us/step - loss: 1.0406 - acc: 0.4684 - val_loss: 1.0398 - val_acc: 0.4696\n",
      "Epoch 62/200\n",
      "14417/14417 [==============================] - 1s 53us/step - loss: 1.0403 - acc: 0.4683 - val_loss: 1.0396 - val_acc: 0.4711\n",
      "Epoch 63/200\n",
      "14417/14417 [==============================] - 1s 69us/step - loss: 1.0401 - acc: 0.4681 - val_loss: 1.0391 - val_acc: 0.4709\n",
      "Epoch 64/200\n",
      "14417/14417 [==============================] - 1s 59us/step - loss: 1.0398 - acc: 0.4688 - val_loss: 1.0391 - val_acc: 0.4694\n",
      "Epoch 65/200\n",
      "14417/14417 [==============================] - 1s 69us/step - loss: 1.0397 - acc: 0.4703 - val_loss: 1.0387 - val_acc: 0.4713\n",
      "Epoch 66/200\n",
      "14417/14417 [==============================] - 1s 88us/step - loss: 1.0394 - acc: 0.4697 - val_loss: 1.0391 - val_acc: 0.4696\n",
      "Epoch 67/200\n",
      "14417/14417 [==============================] - 1s 50us/step - loss: 1.0393 - acc: 0.4706 - val_loss: 1.0383 - val_acc: 0.4705\n",
      "Epoch 68/200\n",
      "14417/14417 [==============================] - 1s 83us/step - loss: 1.0391 - acc: 0.4703 - val_loss: 1.0385 - val_acc: 0.4702\n",
      "Epoch 69/200\n",
      "14417/14417 [==============================] - 1s 83us/step - loss: 1.0390 - acc: 0.4710 - val_loss: 1.0381 - val_acc: 0.4702\n",
      "Epoch 70/200\n",
      "14417/14417 [==============================] - 1s 77us/step - loss: 1.0389 - acc: 0.4694 - val_loss: 1.0379 - val_acc: 0.4700\n",
      "Epoch 71/200\n",
      "14417/14417 [==============================] - 1s 78us/step - loss: 1.0387 - acc: 0.4703 - val_loss: 1.0378 - val_acc: 0.4705\n",
      "Epoch 72/200\n",
      "14417/14417 [==============================] - 1s 81us/step - loss: 1.0385 - acc: 0.4683 - val_loss: 1.0378 - val_acc: 0.4709\n",
      "Epoch 73/200\n",
      "14417/14417 [==============================] - 1s 81us/step - loss: 1.0384 - acc: 0.4699 - val_loss: 1.0378 - val_acc: 0.4711\n",
      "Epoch 74/200\n",
      "14417/14417 [==============================] - 1s 89us/step - loss: 1.0384 - acc: 0.4710 - val_loss: 1.0374 - val_acc: 0.4705\n",
      "Epoch 75/200\n",
      "14417/14417 [==============================] - 1s 84us/step - loss: 1.0380 - acc: 0.4722 - val_loss: 1.0376 - val_acc: 0.4721\n",
      "Epoch 76/200\n",
      "14417/14417 [==============================] - 1s 66us/step - loss: 1.0381 - acc: 0.4706 - val_loss: 1.0373 - val_acc: 0.4696\n",
      "Epoch 77/200\n",
      "14417/14417 [==============================] - 1s 54us/step - loss: 1.0380 - acc: 0.4701 - val_loss: 1.0371 - val_acc: 0.4707\n",
      "Epoch 78/200\n",
      "14417/14417 [==============================] - 1s 49us/step - loss: 1.0378 - acc: 0.4708 - val_loss: 1.0370 - val_acc: 0.4698\n",
      "Epoch 79/200\n",
      "14417/14417 [==============================] - 1s 82us/step - loss: 1.0378 - acc: 0.4710 - val_loss: 1.0369 - val_acc: 0.4709\n",
      "Epoch 80/200\n",
      "14417/14417 [==============================] - 1s 70us/step - loss: 1.0376 - acc: 0.4701 - val_loss: 1.0368 - val_acc: 0.4700\n",
      "Epoch 81/200\n",
      "14417/14417 [==============================] - 1s 54us/step - loss: 1.0376 - acc: 0.4717 - val_loss: 1.0368 - val_acc: 0.4700\n",
      "Epoch 82/200\n",
      "14417/14417 [==============================] - 1s 41us/step - loss: 1.0375 - acc: 0.4717 - val_loss: 1.0370 - val_acc: 0.4730\n",
      "Epoch 83/200\n",
      "14417/14417 [==============================] - 1s 68us/step - loss: 1.0374 - acc: 0.4724 - val_loss: 1.0365 - val_acc: 0.4705\n",
      "Epoch 84/200\n",
      "14417/14417 [==============================] - 1s 54us/step - loss: 1.0374 - acc: 0.4713 - val_loss: 1.0364 - val_acc: 0.4709\n",
      "Epoch 85/200\n",
      "14417/14417 [==============================] - 1s 58us/step - loss: 1.0372 - acc: 0.4715 - val_loss: 1.0369 - val_acc: 0.4736\n",
      "Epoch 86/200\n",
      "14417/14417 [==============================] - 1s 60us/step - loss: 1.0371 - acc: 0.4737 - val_loss: 1.0363 - val_acc: 0.4711\n",
      "Epoch 87/200\n",
      "14417/14417 [==============================] - 1s 65us/step - loss: 1.0371 - acc: 0.4721 - val_loss: 1.0363 - val_acc: 0.4717\n",
      "Epoch 88/200\n",
      "14417/14417 [==============================] - 1s 51us/step - loss: 1.0370 - acc: 0.4724 - val_loss: 1.0362 - val_acc: 0.4727\n",
      "Epoch 89/200\n",
      "14417/14417 [==============================] - 1s 55us/step - loss: 1.0369 - acc: 0.4715 - val_loss: 1.0362 - val_acc: 0.4738\n",
      "Epoch 90/200\n",
      "14417/14417 [==============================] - 1s 55us/step - loss: 1.0367 - acc: 0.4715 - val_loss: 1.0360 - val_acc: 0.4705\n",
      "Epoch 91/200\n",
      "14417/14417 [==============================] - 1s 74us/step - loss: 1.0368 - acc: 0.4722 - val_loss: 1.0362 - val_acc: 0.4738\n",
      "Epoch 92/200\n",
      "14417/14417 [==============================] - 1s 74us/step - loss: 1.0367 - acc: 0.4726 - val_loss: 1.0361 - val_acc: 0.4736\n",
      "Epoch 93/200\n",
      "14417/14417 [==============================] - 1s 54us/step - loss: 1.0366 - acc: 0.4714 - val_loss: 1.0358 - val_acc: 0.4732\n",
      "Epoch 94/200\n",
      "14417/14417 [==============================] - 1s 51us/step - loss: 1.0365 - acc: 0.4711 - val_loss: 1.0361 - val_acc: 0.4730\n",
      "Epoch 95/200\n",
      "14417/14417 [==============================] - 1s 46us/step - loss: 1.0365 - acc: 0.4731 - val_loss: 1.0361 - val_acc: 0.4750\n",
      "Epoch 96/200\n",
      "14417/14417 [==============================] - 1s 52us/step - loss: 1.0365 - acc: 0.4718 - val_loss: 1.0360 - val_acc: 0.4730\n",
      "Epoch 97/200\n",
      "14417/14417 [==============================] - 1s 58us/step - loss: 1.0363 - acc: 0.4728 - val_loss: 1.0355 - val_acc: 0.4711\n",
      "Epoch 98/200\n",
      "14417/14417 [==============================] - 1s 47us/step - loss: 1.0364 - acc: 0.4722 - val_loss: 1.0359 - val_acc: 0.4736\n",
      "Epoch 99/200\n",
      "14417/14417 [==============================] - 1s 59us/step - loss: 1.0363 - acc: 0.4727 - val_loss: 1.0358 - val_acc: 0.4736\n",
      "Epoch 100/200\n",
      "14417/14417 [==============================] - 1s 60us/step - loss: 1.0362 - acc: 0.4720 - val_loss: 1.0356 - val_acc: 0.4752\n",
      "Epoch 101/200\n",
      "14417/14417 [==============================] - 1s 54us/step - loss: 1.0360 - acc: 0.4719 - val_loss: 1.0359 - val_acc: 0.4725\n",
      "Epoch 102/200\n",
      "14417/14417 [==============================] - 1s 50us/step - loss: 1.0361 - acc: 0.4718 - val_loss: 1.0353 - val_acc: 0.4734\n",
      "Epoch 103/200\n",
      "14417/14417 [==============================] - 1s 47us/step - loss: 1.0360 - acc: 0.4719 - val_loss: 1.0354 - val_acc: 0.4752\n",
      "Epoch 104/200\n",
      "14417/14417 [==============================] - 1s 47us/step - loss: 1.0359 - acc: 0.4721 - val_loss: 1.0351 - val_acc: 0.4715\n",
      "Epoch 105/200\n",
      "14417/14417 [==============================] - 1s 62us/step - loss: 1.0357 - acc: 0.4728 - val_loss: 1.0354 - val_acc: 0.4719\n",
      "Epoch 106/200\n",
      "14417/14417 [==============================] - 1s 48us/step - loss: 1.0359 - acc: 0.4730 - val_loss: 1.0355 - val_acc: 0.4750\n",
      "Epoch 107/200\n",
      "14417/14417 [==============================] - 1s 40us/step - loss: 1.0358 - acc: 0.4727 - val_loss: 1.0349 - val_acc: 0.4715\n",
      "Epoch 108/200\n",
      "14417/14417 [==============================] - 1s 42us/step - loss: 1.0358 - acc: 0.4726 - val_loss: 1.0351 - val_acc: 0.4757\n",
      "Epoch 109/200\n",
      "14417/14417 [==============================] - 1s 43us/step - loss: 1.0357 - acc: 0.4712 - val_loss: 1.0352 - val_acc: 0.4744\n",
      "Epoch 110/200\n",
      "14417/14417 [==============================] - 1s 46us/step - loss: 1.0356 - acc: 0.4726 - val_loss: 1.0348 - val_acc: 0.4717\n",
      "Epoch 111/200\n",
      "14417/14417 [==============================] - 1s 44us/step - loss: 1.0356 - acc: 0.4721 - val_loss: 1.0347 - val_acc: 0.4711\n",
      "Epoch 112/200\n",
      "14417/14417 [==============================] - 1s 44us/step - loss: 1.0356 - acc: 0.4733 - val_loss: 1.0347 - val_acc: 0.4723\n",
      "Epoch 113/200\n",
      "14417/14417 [==============================] - 1s 52us/step - loss: 1.0355 - acc: 0.4723 - val_loss: 1.0348 - val_acc: 0.4752\n",
      "Epoch 114/200\n",
      "14417/14417 [==============================] - 1s 68us/step - loss: 1.0355 - acc: 0.4733 - val_loss: 1.0348 - val_acc: 0.4757\n",
      "Epoch 115/200\n",
      "14417/14417 [==============================] - 1s 99us/step - loss: 1.0353 - acc: 0.4729 - val_loss: 1.0347 - val_acc: 0.4717\n",
      "Epoch 116/200\n",
      "14417/14417 [==============================] - 1s 71us/step - loss: 1.0354 - acc: 0.4713 - val_loss: 1.0345 - val_acc: 0.4744\n",
      "Epoch 117/200\n",
      "14417/14417 [==============================] - 1s 60us/step - loss: 1.0353 - acc: 0.4725 - val_loss: 1.0345 - val_acc: 0.4738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "14417/14417 [==============================] - 1s 57us/step - loss: 1.0353 - acc: 0.4732 - val_loss: 1.0347 - val_acc: 0.4757\n",
      "Epoch 119/200\n",
      "14417/14417 [==============================] - 1s 50us/step - loss: 1.0352 - acc: 0.4733 - val_loss: 1.0346 - val_acc: 0.4750\n",
      "Epoch 120/200\n",
      "14417/14417 [==============================] - 1s 63us/step - loss: 1.0351 - acc: 0.4728 - val_loss: 1.0347 - val_acc: 0.4744\n",
      "Epoch 121/200\n",
      "14417/14417 [==============================] - 1s 69us/step - loss: 1.0350 - acc: 0.4725 - val_loss: 1.0346 - val_acc: 0.4742\n",
      "Epoch 122/200\n",
      "14417/14417 [==============================] - 1s 48us/step - loss: 1.0351 - acc: 0.4723 - val_loss: 1.0344 - val_acc: 0.4748\n",
      "Epoch 123/200\n",
      "14417/14417 [==============================] - 1s 45us/step - loss: 1.0350 - acc: 0.4727 - val_loss: 1.0342 - val_acc: 0.4742\n",
      "Epoch 124/200\n",
      "14417/14417 [==============================] - 1s 43us/step - loss: 1.0350 - acc: 0.4739 - val_loss: 1.0342 - val_acc: 0.4711\n",
      "Epoch 125/200\n",
      "14417/14417 [==============================] - 1s 40us/step - loss: 1.0349 - acc: 0.4724 - val_loss: 1.0343 - val_acc: 0.4725\n",
      "Epoch 126/200\n",
      "14417/14417 [==============================] - 1s 42us/step - loss: 1.0349 - acc: 0.4738 - val_loss: 1.0344 - val_acc: 0.4754\n",
      "Epoch 127/200\n",
      "14417/14417 [==============================] - 1s 42us/step - loss: 1.0349 - acc: 0.4730 - val_loss: 1.0342 - val_acc: 0.4725\n",
      "Epoch 128/200\n",
      "14417/14417 [==============================] - 1s 41us/step - loss: 1.0348 - acc: 0.4731 - val_loss: 1.0341 - val_acc: 0.4707\n",
      "Epoch 129/200\n",
      "14417/14417 [==============================] - 1s 42us/step - loss: 1.0348 - acc: 0.4727 - val_loss: 1.0342 - val_acc: 0.4750\n",
      "Epoch 130/200\n",
      "14417/14417 [==============================] - 1s 43us/step - loss: 1.0347 - acc: 0.4733 - val_loss: 1.0340 - val_acc: 0.4725\n",
      "Epoch 131/200\n",
      "14417/14417 [==============================] - 1s 41us/step - loss: 1.0346 - acc: 0.4750 - val_loss: 1.0347 - val_acc: 0.4761\n",
      "Epoch 132/200\n",
      "14417/14417 [==============================] - 1s 41us/step - loss: 1.0347 - acc: 0.4735 - val_loss: 1.0341 - val_acc: 0.4736\n",
      "Epoch 133/200\n",
      "14417/14417 [==============================] - 1s 40us/step - loss: 1.0347 - acc: 0.4733 - val_loss: 1.0340 - val_acc: 0.4744\n",
      "Epoch 134/200\n",
      "14417/14417 [==============================] - 1s 40us/step - loss: 1.0345 - acc: 0.4752 - val_loss: 1.0340 - val_acc: 0.4717\n",
      "Epoch 135/200\n",
      "14417/14417 [==============================] - 1s 39us/step - loss: 1.0346 - acc: 0.4734 - val_loss: 1.0340 - val_acc: 0.4734\n",
      "Epoch 136/200\n",
      "14417/14417 [==============================] - 1s 40us/step - loss: 1.0346 - acc: 0.4724 - val_loss: 1.0340 - val_acc: 0.4746\n",
      "Epoch 137/200\n",
      "14417/14417 [==============================] - 1s 41us/step - loss: 1.0345 - acc: 0.4720 - val_loss: 1.0338 - val_acc: 0.4736\n",
      "Epoch 138/200\n",
      "14417/14417 [==============================] - 1s 45us/step - loss: 1.0345 - acc: 0.4731 - val_loss: 1.0338 - val_acc: 0.4740\n",
      "Epoch 139/200\n",
      "14417/14417 [==============================] - 1s 40us/step - loss: 1.0343 - acc: 0.4745 - val_loss: 1.0340 - val_acc: 0.4773\n",
      "Epoch 140/200\n",
      "14417/14417 [==============================] - 1s 41us/step - loss: 1.0343 - acc: 0.4728 - val_loss: 1.0345 - val_acc: 0.4771\n",
      "Epoch 141/200\n",
      "14417/14417 [==============================] - 1s 41us/step - loss: 1.0343 - acc: 0.4745 - val_loss: 1.0337 - val_acc: 0.4725\n",
      "Epoch 142/200\n",
      "14417/14417 [==============================] - 1s 40us/step - loss: 1.0344 - acc: 0.4743 - val_loss: 1.0336 - val_acc: 0.4740\n",
      "Epoch 143/200\n",
      "14417/14417 [==============================] - 1s 53us/step - loss: 1.0343 - acc: 0.4731 - val_loss: 1.0339 - val_acc: 0.4769\n",
      "Epoch 144/200\n",
      "14417/14417 [==============================] - 1s 47us/step - loss: 1.0343 - acc: 0.4734 - val_loss: 1.0341 - val_acc: 0.4779\n",
      "Epoch 145/200\n",
      "14417/14417 [==============================] - 1s 41us/step - loss: 1.0342 - acc: 0.4738 - val_loss: 1.0335 - val_acc: 0.4727\n",
      "Epoch 146/200\n",
      "14417/14417 [==============================] - 1s 43us/step - loss: 1.0342 - acc: 0.4737 - val_loss: 1.0337 - val_acc: 0.4754\n",
      "Epoch 147/200\n",
      "14417/14417 [==============================] - 1s 48us/step - loss: 1.0342 - acc: 0.4732 - val_loss: 1.0341 - val_acc: 0.4779\n",
      "Epoch 148/200\n",
      "14417/14417 [==============================] - 1s 48us/step - loss: 1.0342 - acc: 0.4732 - val_loss: 1.0336 - val_acc: 0.4740\n",
      "Epoch 149/200\n",
      "14417/14417 [==============================] - 1s 44us/step - loss: 1.0342 - acc: 0.4731 - val_loss: 1.0334 - val_acc: 0.4752\n",
      "Epoch 150/200\n",
      "14417/14417 [==============================] - 1s 47us/step - loss: 1.0341 - acc: 0.4719 - val_loss: 1.0341 - val_acc: 0.4769\n",
      "Epoch 151/200\n",
      "14417/14417 [==============================] - 1s 40us/step - loss: 1.0341 - acc: 0.4719 - val_loss: 1.0335 - val_acc: 0.4750\n",
      "Epoch 152/200\n",
      "14417/14417 [==============================] - 1s 40us/step - loss: 1.0341 - acc: 0.4731 - val_loss: 1.0334 - val_acc: 0.4721\n",
      "Epoch 153/200\n",
      "14417/14417 [==============================] - 1s 40us/step - loss: 1.0340 - acc: 0.4725 - val_loss: 1.0346 - val_acc: 0.4752\n",
      "Epoch 154/200\n",
      "14417/14417 [==============================] - 1s 42us/step - loss: 1.0340 - acc: 0.4725 - val_loss: 1.0337 - val_acc: 0.4769\n",
      "Epoch 155/200\n",
      "14417/14417 [==============================] - 1s 66us/step - loss: 1.0340 - acc: 0.4728 - val_loss: 1.0338 - val_acc: 0.4775\n",
      "Epoch 156/200\n",
      "14417/14417 [==============================] - 1s 39us/step - loss: 1.0338 - acc: 0.4730 - val_loss: 1.0337 - val_acc: 0.4713\n",
      "Epoch 157/200\n",
      "14417/14417 [==============================] - 1s 41us/step - loss: 1.0340 - acc: 0.4724 - val_loss: 1.0337 - val_acc: 0.4773\n",
      "Epoch 158/200\n",
      "14417/14417 [==============================] - 1s 39us/step - loss: 1.0339 - acc: 0.4733 - val_loss: 1.0336 - val_acc: 0.4738\n",
      "Epoch 159/200\n",
      "14417/14417 [==============================] - 1s 40us/step - loss: 1.0339 - acc: 0.4729 - val_loss: 1.0332 - val_acc: 0.4715\n",
      "Epoch 160/200\n",
      "14417/14417 [==============================] - 1s 42us/step - loss: 1.0338 - acc: 0.4733 - val_loss: 1.0334 - val_acc: 0.4767\n",
      "Epoch 161/200\n",
      "14417/14417 [==============================] - 1s 41us/step - loss: 1.0339 - acc: 0.4727 - val_loss: 1.0333 - val_acc: 0.4769\n",
      "Epoch 162/200\n",
      "14417/14417 [==============================] - 1s 45us/step - loss: 1.0337 - acc: 0.4728 - val_loss: 1.0338 - val_acc: 0.4782\n",
      "Epoch 163/200\n",
      "14417/14417 [==============================] - 1s 57us/step - loss: 1.0339 - acc: 0.4733 - val_loss: 1.0332 - val_acc: 0.4740\n",
      "Epoch 164/200\n",
      "14417/14417 [==============================] - 1s 50us/step - loss: 1.0337 - acc: 0.4720 - val_loss: 1.0331 - val_acc: 0.4721\n",
      "Epoch 165/200\n",
      "14417/14417 [==============================] - 1s 56us/step - loss: 1.0337 - acc: 0.4722 - val_loss: 1.0335 - val_acc: 0.4763\n",
      "Epoch 166/200\n",
      "14417/14417 [==============================] - 1s 53us/step - loss: 1.0337 - acc: 0.4717 - val_loss: 1.0331 - val_acc: 0.4715\n",
      "Epoch 167/200\n",
      "14417/14417 [==============================] - 1s 71us/step - loss: 1.0337 - acc: 0.4724 - val_loss: 1.0333 - val_acc: 0.4727\n",
      "Epoch 168/200\n",
      "14417/14417 [==============================] - 1s 55us/step - loss: 1.0337 - acc: 0.4744 - val_loss: 1.0332 - val_acc: 0.4744\n",
      "Epoch 169/200\n",
      "14417/14417 [==============================] - 1s 47us/step - loss: 1.0337 - acc: 0.4735 - val_loss: 1.0332 - val_acc: 0.4775\n",
      "Epoch 170/200\n",
      "14417/14417 [==============================] - 1s 44us/step - loss: 1.0337 - acc: 0.4733 - val_loss: 1.0330 - val_acc: 0.4740\n",
      "Epoch 171/200\n",
      "14417/14417 [==============================] - 1s 40us/step - loss: 1.0335 - acc: 0.4746 - val_loss: 1.0331 - val_acc: 0.4727\n",
      "Epoch 172/200\n",
      "14417/14417 [==============================] - 1s 40us/step - loss: 1.0336 - acc: 0.4726 - val_loss: 1.0332 - val_acc: 0.4786\n",
      "Epoch 173/200\n",
      "14417/14417 [==============================] - 1s 52us/step - loss: 1.0335 - acc: 0.4730 - val_loss: 1.0332 - val_acc: 0.4719\n",
      "Epoch 174/200\n",
      "14417/14417 [==============================] - 1s 82us/step - loss: 1.0337 - acc: 0.4729 - val_loss: 1.0332 - val_acc: 0.4784\n",
      "Epoch 175/200\n",
      "14417/14417 [==============================] - 1s 66us/step - loss: 1.0335 - acc: 0.4726 - val_loss: 1.0330 - val_acc: 0.4759\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14417/14417 [==============================] - 1s 41us/step - loss: 1.0335 - acc: 0.4732 - val_loss: 1.0333 - val_acc: 0.4777\n",
      "Epoch 177/200\n",
      "14417/14417 [==============================] - 1s 79us/step - loss: 1.0336 - acc: 0.4730 - val_loss: 1.0334 - val_acc: 0.4790\n",
      "Epoch 178/200\n",
      "14417/14417 [==============================] - 1s 54us/step - loss: 1.0336 - acc: 0.4740 - val_loss: 1.0329 - val_acc: 0.4738\n",
      "Epoch 179/200\n",
      "14417/14417 [==============================] - 1s 80us/step - loss: 1.0336 - acc: 0.4740 - val_loss: 1.0331 - val_acc: 0.4773\n",
      "Epoch 180/200\n",
      "14417/14417 [==============================] - 1s 71us/step - loss: 1.0335 - acc: 0.4731 - val_loss: 1.0332 - val_acc: 0.4742\n",
      "Epoch 181/200\n",
      "14417/14417 [==============================] - 1s 72us/step - loss: 1.0336 - acc: 0.4727 - val_loss: 1.0332 - val_acc: 0.4769\n",
      "Epoch 182/200\n",
      "14417/14417 [==============================] - 1s 53us/step - loss: 1.0335 - acc: 0.4740 - val_loss: 1.0331 - val_acc: 0.4782\n",
      "Epoch 183/200\n",
      "14417/14417 [==============================] - 1s 42us/step - loss: 1.0335 - acc: 0.4732 - val_loss: 1.0329 - val_acc: 0.4744\n",
      "Epoch 184/200\n",
      "14417/14417 [==============================] - 1s 47us/step - loss: 1.0333 - acc: 0.4731 - val_loss: 1.0337 - val_acc: 0.4769\n",
      "Epoch 185/200\n",
      "14417/14417 [==============================] - 1s 46us/step - loss: 1.0334 - acc: 0.4743 - val_loss: 1.0328 - val_acc: 0.4734\n",
      "Epoch 186/200\n",
      "14417/14417 [==============================] - 1s 45us/step - loss: 1.0333 - acc: 0.4736 - val_loss: 1.0329 - val_acc: 0.4736\n",
      "Epoch 187/200\n",
      "14417/14417 [==============================] - 1s 51us/step - loss: 1.0335 - acc: 0.4730 - val_loss: 1.0332 - val_acc: 0.4790\n",
      "Epoch 188/200\n",
      "14417/14417 [==============================] - 1s 50us/step - loss: 1.0334 - acc: 0.4726 - val_loss: 1.0332 - val_acc: 0.4790\n",
      "Epoch 189/200\n",
      "14417/14417 [==============================] - 1s 47us/step - loss: 1.0333 - acc: 0.4727 - val_loss: 1.0331 - val_acc: 0.4790\n",
      "Epoch 190/200\n",
      "14417/14417 [==============================] - 1s 49us/step - loss: 1.0334 - acc: 0.4719 - val_loss: 1.0337 - val_acc: 0.4771\n",
      "Epoch 191/200\n",
      "14417/14417 [==============================] - 1s 45us/step - loss: 1.0335 - acc: 0.4724 - val_loss: 1.0332 - val_acc: 0.4790\n",
      "Epoch 192/200\n",
      "14417/14417 [==============================] - 1s 45us/step - loss: 1.0333 - acc: 0.4730 - val_loss: 1.0331 - val_acc: 0.4730\n",
      "Epoch 193/200\n",
      "14417/14417 [==============================] - 1s 58us/step - loss: 1.0333 - acc: 0.4729 - val_loss: 1.0334 - val_acc: 0.4790\n",
      "Epoch 194/200\n",
      "14417/14417 [==============================] - 1s 56us/step - loss: 1.0333 - acc: 0.4734 - val_loss: 1.0330 - val_acc: 0.4779\n",
      "Epoch 195/200\n",
      "14417/14417 [==============================] - 1s 47us/step - loss: 1.0332 - acc: 0.4743 - val_loss: 1.0330 - val_acc: 0.4746\n",
      "Epoch 196/200\n",
      "14417/14417 [==============================] - 1s 52us/step - loss: 1.0333 - acc: 0.4739 - val_loss: 1.0328 - val_acc: 0.4750\n",
      "Epoch 197/200\n",
      "14417/14417 [==============================] - 1s 50us/step - loss: 1.0332 - acc: 0.4732 - val_loss: 1.0327 - val_acc: 0.4740\n",
      "Epoch 198/200\n",
      "14417/14417 [==============================] - 1s 43us/step - loss: 1.0333 - acc: 0.4719 - val_loss: 1.0330 - val_acc: 0.4779\n",
      "Epoch 199/200\n",
      "14417/14417 [==============================] - 1s 42us/step - loss: 1.0333 - acc: 0.4726 - val_loss: 1.0330 - val_acc: 0.4734\n",
      "Epoch 200/200\n",
      "14417/14417 [==============================] - 1s 59us/step - loss: 1.0332 - acc: 0.4731 - val_loss: 1.0329 - val_acc: 0.4782\n"
     ]
    }
   ],
   "source": [
    "fitted = network.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "network.save('model_mlp3.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a2ceaeef0>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = fitted \n",
    "   \n",
    "print(history.history.keys())  \n",
    "   \n",
    "plt.figure(1)  \n",
    "   \n",
    "# summarize history for accuracy  \n",
    "   \n",
    "plt.subplot(211)  \n",
    "plt.plot(history.history['acc'],color ='black',linestyle='dashed')  \n",
    "plt.plot(history.history['val_acc'],color ='grey',linestyle='solid')  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "#plt.savefig('model-12-1.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a2bd05c18>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " # summarize history for loss  \n",
    "\n",
    "plt.subplot(212)  \n",
    "\n",
    "plt.plot(history.history['loss'],color ='black',linestyle='dashed')  \n",
    "plt.plot(history.history['val_loss'],color ='grey',linestyle='solid')  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "#plt.savefig('model-12-2.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4806/4806 [==============================] - 0s 30us/step\n",
      "\n",
      "Loss = \t\t1.027355612440502\n",
      "Accuracy = \t0.4787765293383271\n",
      "Random \t= \t0.33\n"
     ]
    }
   ],
   "source": [
    "scores = network.evaluate(X_test, y_test)\n",
    "loss = scores[0]\n",
    "accuracy = scores[1]\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Loss = \\t\\t{}\".format(loss))\n",
    "print(\"Accuracy = \\t{}\".format(accuracy))\n",
    "print(\"Random \\t= \\t0.33\")\n",
    "#print(\"On Distr = \\t{}\".format(df.label.value_counts()[0]/sum(df.label.value_counts())*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
